{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>RQ3</center></h1>\n",
    "<center>Marcel de Cabanyes Torras</center>\n",
    "<center> 207526</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/marcel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy.sparse as sparse\n",
    "import implicit\n",
    "import os.path\n",
    "import sys\n",
    "parent_dir = os.path.dirname(os.getcwd())\n",
    "sys.path.append(os.path.join(parent_dir, 'search-engine/')) #Load utils.py from search-engine/\n",
    "from utils import *\n",
    "import igraph\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(parent_dir, 'search-engine/data') #Load data from search-engine/data\n",
    "df_tweets = load_df(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retain only retweets (note that we use a subsample to do all the process feasible for our machine)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_retweets = df_tweets[~pd.isnull(df_tweets['retweeted_status'])][:10000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to DataFrame with source and destination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>23560243-596b-501a-8c17-ce8454fde1c1</td>\n",
       "      <td>89351f88-728f-5e9a-a481-45513502cb51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>eb71fc65-45e0-55de-ad32-c7f8bc4a950b</td>\n",
       "      <td>c500f6b6-cec5-576b-98d0-6714c6f533ea</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>e7bbce28-564c-51c8-96e6-314bf2c1a5b6</td>\n",
       "      <td>403e43ea-81b6-5f1b-b65c-1ab0c0ec6632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>9f1f2dee-b578-54fc-bcca-f8bbb2e45473</td>\n",
       "      <td>c6baa608-68fc-5709-8e87-2d65015fa9c0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>caddecbc-2b0d-5dcb-aafd-064fff61f347</td>\n",
       "      <td>9e561cff-70fc-5e61-b8bc-b017a4641211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 source                           destination\n",
       "0  23560243-596b-501a-8c17-ce8454fde1c1  89351f88-728f-5e9a-a481-45513502cb51\n",
       "1  eb71fc65-45e0-55de-ad32-c7f8bc4a950b  c500f6b6-cec5-576b-98d0-6714c6f533ea\n",
       "2  e7bbce28-564c-51c8-96e6-314bf2c1a5b6  403e43ea-81b6-5f1b-b65c-1ab0c0ec6632\n",
       "3  9f1f2dee-b578-54fc-bcca-f8bbb2e45473  c6baa608-68fc-5709-8e87-2d65015fa9c0\n",
       "4  caddecbc-2b0d-5dcb-aafd-064fff61f347  9e561cff-70fc-5e61-b8bc-b017a4641211"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_graph = pd.DataFrame(columns=[\"source\", \"destination\"])\n",
    "# take the user and the user retweeted anonymizing them\n",
    "df_graph[\"source\"] = [str(uuid.uuid5(uuid.NAMESPACE_OID,user['screen_name'])) for user in df_retweets['user']]\n",
    "df_graph[\"destination\"] = [str(uuid.uuid5(uuid.NAMESPACE_OID,user['user']['screen_name'])) for user in df_retweets['retweeted_status']]\n",
    "df_graph.drop_duplicates(inplace=True)\n",
    "df_graph.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to list of tuples and then to undirected graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuples = [tuple(x) for x in df_graph.values]\n",
    "graph = igraph.Graph.TupleList(tuples, directed = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into test and train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get index of edges at random from the graph (20%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.2\n",
    "N = len(graph.es)\n",
    "all_idxs = range(N)\n",
    "test_idxs = list(np.random.choice(a=all_idxs, size=int(p*N), replace=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add edges to trainlist if not in test, and reverse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlist = list()\n",
    "testlist = list()\n",
    "train_idxs = []\n",
    "for idx, one_edge in enumerate(graph.es):\n",
    "    n1 = one_edge.source\n",
    "    n2 = one_edge.target\n",
    "    if idx not in test_idxs:\n",
    "        trainlist.append((n1, n2))\n",
    "        train_idxs.append(idx)\n",
    "    else:\n",
    "        testlist.append((n1, n2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create train_graph from train_idxs, and test_graph from test_idxs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_graph = graph.subgraph_edges(train_idxs)\n",
    "test_graph = graph.subgraph_edges(test_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute some statisctics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary statistics of complete graph:\n",
      "    Number of nodes: 12656\n",
      "    Number of edges: 9868\n",
      "    Average degree: 1.56\n",
      "Summary statistics of train graph:\n",
      "    Number of nodes: 10364\n",
      "    Number of edges: 7895\n",
      "    Average degree: 1.52\n",
      "Summary statistics of test graph:\n",
      "    Number of nodes: 2975\n",
      "    Number of edges: 1973\n",
      "    Average degree: 1.33\n"
     ]
    }
   ],
   "source": [
    "print('Summary statistics of complete graph:')\n",
    "print('    Number of nodes: {}'.format(len(graph.vs())))\n",
    "print('    Number of edges: {}'.format(len(graph.es())))\n",
    "print('    Average degree: {}'.format(round(np.mean(graph.degree()),2)))\n",
    "\n",
    "print('Summary statistics of train graph:')\n",
    "print('    Number of nodes: {}'.format(len(train_graph.vs())))\n",
    "print('    Number of edges: {}'.format(len(train_graph.es())))\n",
    "print('    Average degree: {}'.format(round(np.mean(train_graph.degree()),2)))\n",
    "\n",
    "print('Summary statistics of test graph:')\n",
    "print('    Number of nodes: {}'.format(len(test_graph.vs())))\n",
    "print('    Number of edges: {}'.format(len(test_graph.es())))\n",
    "print('    Average degree: {}'.format(round(np.mean(test_graph.degree()),2)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List indexes of edges in test_idxs whose node is not in the trainlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_nodes = [edge[0] for edge in trainlist] + [edge[1] for edge in trainlist]\n",
    "idxs_to_drop = []\n",
    "for i, (n1, n2) in enumerate(testlist):\n",
    "    if not n1 in train_nodes or not n2 in train_nodes:\n",
    "        idxs_to_drop.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preserve only those edges of nodes present in trainlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_idxs = [i for j, i in enumerate(test_idxs) if j not in idxs_to_drop]\n",
    "testlist = [i for j, i in enumerate(testlist) if j not in idxs_to_drop]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`igraph` has created new indices for the nodes in our train_graph subgraph. Here we define a pair of functions that will help us switch between the indices of the original graph (used in trainlist, groundtruth, potentialrecommentations) and the indices of the subgraph train_graph (which will be used to train the model). It uses the name of the node (which is the user in the tweet) to identify the indices and do the \"translation\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapping_graph_to_subgraph(graph, subgraph, index):\n",
    "    \"\"\"\n",
    "    Function to map node index in original graph to node index in the subraph\n",
    "    \"\"\"\n",
    "    node_name = graph.vs[index]['name']\n",
    "    for i, name in enumerate(subgraph.vs['name']):\n",
    "        if name == node_name:\n",
    "            return i\n",
    "        \n",
    "def mapping_subgraph_to_graph(graph, subgraph, index):\n",
    "    \"\"\"\n",
    "    Function to map node index in subgraph to node index in the original graph\n",
    "    \"\"\"\n",
    "    node_name = subgraph.vs[index]['name']\n",
    "    for i, name in enumerate(graph.vs['name']):\n",
    "        if name == node_name:\n",
    "            return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get potential recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get set of potential recommendations: nodes at exact distance 2 for each node of the testlist that is also present in testlist (we do not care about the recommendations for \"source\" nodes that are not in the testlist)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nodes_at_distance_2(graph, train_graph, testlist):\n",
    "    \"\"\"\n",
    "    starting from a graph this function returns all the nodes at distance 2 \n",
    "    from nodes also present in the testlist\n",
    "    \"\"\"\n",
    "    \n",
    "    all_potential_recommendations = set()\n",
    "    \n",
    "    # get all nodes from the testlist\n",
    "    test_nodes = [edge[0] for edge in testlist] + [edge[1] for edge in testlist]\n",
    "    \n",
    "    for n1 in train_graph.vs:\n",
    "        \n",
    "        # map to the original grap and check if in test_nodes\n",
    "        n1_index = mapping_subgraph_to_graph(graph, train_graph, n1.index)\n",
    "        \n",
    "        if n1_index in test_nodes:\n",
    "            # all the nodes at distance 1\n",
    "            nodes_at_most_distant_1 = set(train_graph.neighborhood(vertices=n1, order=1))\n",
    "\n",
    "            # all the nodes at distance 1 and distance 2\n",
    "\n",
    "            nodes_at_most_distant_2 = set(train_graph.neighborhood(vertices=n1, order=2))\n",
    "\n",
    "            # only the nodes at distance 2\n",
    "            only_nodes_at_distance_2 = nodes_at_most_distant_2 - nodes_at_most_distant_1\n",
    "\n",
    "\n",
    "            # check if empty set\n",
    "            if len(only_nodes_at_distance_2) > 0:\n",
    "\n",
    "\n",
    "                for n2 in only_nodes_at_distance_2:\n",
    "                    # map to the original grap\n",
    "                    n2_index = mapping_subgraph_to_graph(graph, train_graph, n2)\n",
    "                    all_potential_recommendations.add((n1_index, n2_index))\n",
    "            \n",
    "    return all_potential_recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_potential_recommendations = find_nodes_at_distance_2(graph, train_graph, testlist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the ground truth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the edges of testlist to ground_truth as `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = set()\n",
    "for n1, n2 in testlist:\n",
    "    ground_truth.add((n1, n2, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the edges of potential recommendations not already present in ground_truth as `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n1, n2 in all_potential_recommendations:\n",
    "    if (n1,n2,1) not in ground_truth:\n",
    "        ground_truth.add((n1,n2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a dictionary from the ground_truth set (it will be useful in the evaluation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_friends_dict = defaultdict(list)\n",
    "count = 0\n",
    "for n1, n2, edge in ground_truth:\n",
    "    if edge:\n",
    "        ground_truth_friends_dict[n1].append(n2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alternating Least Squares prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create, from the adjency matrix of the train_graph, an sparse one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = train_graph.get_adjacency().data\n",
    "M = csr_matrix(M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and fit it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe04f50995af487c8673f1d91a713f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=5), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = implicit.als.AlternatingLeastSquares(factors=10, calculate_training_loss=True,  iterations=5)\n",
    "model.fit(M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ALS(testset, model, graph, train_graph):\n",
    "    \"\"\"\n",
    "    predict ALS\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the empty list\n",
    "    all_predictions = []\n",
    "\n",
    "    # scroll the obs\n",
    "    for n1,n2, w in testset:\n",
    "        \n",
    "        # map testset index to subraph index\n",
    "        n1_subgraph = mapping_graph_to_subgraph(graph, train_graph, n1)\n",
    "        n2_subgraph = mapping_graph_to_subgraph(graph, train_graph, n2)\n",
    "\n",
    "        # take here the low-dimensional vectors returned by the matrix factorization\n",
    "        \n",
    "        array_n1 = model.user_factors[n1_subgraph,:]\n",
    "        array_n2 = model.item_factors[n2_subgraph,:]\n",
    "\n",
    "        # multiplying these vectors we generate an approximation for the edge score\n",
    "        one_p = np.dot(array_n1, array_n2)\n",
    "\n",
    "        all_predictions.append(one_p)\n",
    "        \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict the friendships and create a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "df_als = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "all_predictions = predict_ALS(df_als.values, model, graph, train_graph)\n",
    "df_als[\"rating\"] = all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adamic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ADA(u,v, graph):\n",
    "    \"\"\"\n",
    "    compute adamic-adar from scratch\n",
    "    \"\"\"\n",
    "    \n",
    "    # set of neighbors of u\n",
    "    outlinks_from_u = graph.neighbors(u)\n",
    "\n",
    "    # set of neighbors of v\n",
    "    inlinks_to_v = graph.neighbors(u)\n",
    "\n",
    "    \n",
    "    # set Z of neighbors of both\n",
    "    bridges = set(outlinks_from_u).intersection(inlinks_to_v)\n",
    "\n",
    "    # degree of nodes in set Z\n",
    "    deg_ = [graph.degree(n) for n in bridges]\n",
    "    \n",
    "    # computing the reciprocal in log-scale\n",
    "    out = [1./np.log2(dd+1) for dd in deg_]\n",
    "\n",
    "    return sum(out)\n",
    "\n",
    "def predict_ADA(testset, graph, train_graph):\n",
    "    \"\"\"\n",
    "    predict ada\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the empty list\n",
    "    all_predictions = []\n",
    "\n",
    "    # scroll the obs\n",
    "    for n1,n2, w in testset:\n",
    "        \n",
    "        # map indices from grpah to subraph\n",
    "        n1_subgraph = mapping_graph_to_subgraph(graph, train_graph, n1)\n",
    "        n2_subgraph = mapping_graph_to_subgraph(graph, train_graph, n2)\n",
    "        \n",
    "        # compute the adamic score for n1 and n2\n",
    "        one_p = compute_ADA(n1_subgraph, n2_subgraph, train_graph)\n",
    "\n",
    "        all_predictions.append(one_p)\n",
    "        \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "df_ada = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "all_predictions = predict_ADA(df_ada.values, graph, train_graph)\n",
    "df_ada[\"rating\"] = all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jaccard similarity based prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_Jaccard(u,v, graph):\n",
    "    \"\"\"\n",
    "    compute jaccard similarity\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # set of neighbors of u\n",
    "    outlinks_from_u = graph.neighbors(u)\n",
    "\n",
    "    # set of neighbors of v\n",
    "    inlinks_to_v = graph.neighbors(v)\n",
    "\n",
    "    # intesection of the two sets\n",
    "    num = set(outlinks_from_u).intersection(inlinks_to_v)\n",
    "\n",
    "    # union of the two sets\n",
    "    den = set(outlinks_from_u).union(inlinks_to_v)\n",
    "    \n",
    "    # final division\n",
    "    out = len(num)/len(den)\n",
    "    \n",
    "    return out\n",
    "\n",
    "def predict_Jaccard(testset, graph, train_graph):\n",
    "    \"\"\"\n",
    "    Predict Jaccard\n",
    "    \"\"\"\n",
    "\n",
    "    # initialize the empty list\n",
    "    all_predictions = []\n",
    "\n",
    "    # scroll the obs\n",
    "    for n1,n2, w in testset:\n",
    "        \n",
    "        # map indices from grpah to subraph\n",
    "        n1_subgraph = mapping_graph_to_subgraph(graph, train_graph, n1)\n",
    "        n2_subgraph = mapping_graph_to_subgraph(graph, train_graph, n2)\n",
    "        \n",
    "        # compute the jaccard similarity score for n1 and n2\n",
    "        one_p = compute_Jaccard(n1_subgraph, n2_subgraph, train_graph)\n",
    "\n",
    "        all_predictions.append(one_p)\n",
    "        \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "df_j = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "all_predictions = predict_Jaccard(df_j.values, graph, train_graph)\n",
    "df_j[\"rating\"] = all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Page-rank prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_page_rank(graph, ground_truth, train_graph):\n",
    "    \"\"\"\n",
    "    Predict page-rank\n",
    "    \"\"\"\n",
    "    # Create dictionary from the ground truth node -> friends\n",
    "    page_rank_dict = defaultdict(list)\n",
    "    \n",
    "    for u, v, w in ground_truth:\n",
    "        page_rank_dict[u].append(v)\n",
    "    all_predictions = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    lines = len(page_rank_dict)\n",
    "    \n",
    "    # scroll the obs\n",
    "    for n1 in page_rank_dict:\n",
    "        # compute the personalized pagerank for n1 \n",
    "        n1_subgraph = mapping_graph_to_subgraph(graph, train_graph, n1)\n",
    "        personalized_pr = train_graph.personalized_pagerank(reset_vertices=n1_subgraph)\n",
    "        # compute the score for n2\n",
    "        for n2 in page_rank_dict[n1]:\n",
    "            n2_subgraph = mapping_graph_to_subgraph(graph, train_graph, n2)\n",
    "            all_predictions.append((n1,n2,personalized_pr[n2_subgraph]))\n",
    "        count += 1 \n",
    "        if count%1000==0:\n",
    "            print(\"{}% processed.\".format(round(count/lines,2)))\n",
    "    print(\"100% processed.\")\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processed.\n"
     ]
    }
   ],
   "source": [
    "# generate the predictions\n",
    "all_predictions = predict_page_rank(graph, ground_truth, train_graph)\n",
    "df_pr = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "df_predict = pd.DataFrame(list(all_predictions), columns=[\"n1\",\"n2\", \"rating\"])\n",
    "# merge dataframes in order to have the same format as the other models\n",
    "df_pr = pd.merge(df_pr, df_predict, how='left', on=['n1', 'n2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populary-based prediction (personal model)\n",
    "### RQ 3B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly we create a dictionary user to node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "user_to_node_dict = defaultdict()\n",
    "for edge in graph.es:\n",
    "    try:\n",
    "        user_to_node_dict[df_graph.loc[i]['source']] = edge.source\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        user_to_node_dict[df_graph.loc[i]['destination']] =  edge.target   \n",
    "    except:\n",
    "        pass\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class populary_based_prediction():\n",
    "    \"\"\"\n",
    "    This model is based on popularity of the retweeted tweet, it computes the logs (for scale) of the sum \n",
    "    of favourited_count and retweet_count and assigns the result to the retweeted user (in a dictionary). \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.predictor = defaultdict()\n",
    "    \n",
    "    def fit(self, user_to_node_dict, data):        \n",
    "        \n",
    "        for i, row in data.iterrows():\n",
    "            quoted_tweet = row['quoted_status'] # get the favorited_count and retweet count for the\n",
    "            # retweeted user tweet\n",
    "            if not pd.isnull(quoted_tweet):\n",
    "                popularity = quoted_tweet['favorite_count'] + quoted_tweet['retweet_count']\n",
    "                try: # remember that the users had been anonymized\n",
    "                    if popularity != 0: # assign the score to the user (as node number)\n",
    "                        self.predictor[user_to_node_dict[str(uuid.uuid5(uuid.NAMESPACE_OID,row['user']['screen_name']))]] = np.log10(popularity)\n",
    "                    else:\n",
    "                        self.predictor[user_to_node_dict[str(uuid.uuid5(uuid.NAMESPACE_OID,row['user']['screen_name']))]] = 0\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "def predict_pop(ground_truth, model):\n",
    "    \"\"\"\n",
    "    predict for a list of observations the score for adding/removing a link\n",
    "    \"\"\"\n",
    "    # Create dictionary from the ground truth node -> friends\n",
    "    pop_dict = defaultdict(list)\n",
    "    \n",
    "    for u, v, w in ground_truth:\n",
    "        pop_dict[u].append(v)\n",
    "    all_predictions = []\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    lines = len(pop_dict)\n",
    "    \n",
    "    # scroll the obs\n",
    "    for n1 in pop_dict:\n",
    "        # compute the score for n2\n",
    "        for n2 in pop_dict[n1]:\n",
    "            if n2 in model.predictor:\n",
    "                all_predictions.append((n1,n2,model.predictor[n2]))\n",
    "            else:\n",
    "                all_predictions.append((n1,n2,0))\n",
    "    \n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = populary_based_prediction()\n",
    "model.fit(user_to_node_dict, df_retweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the predictions\n",
    "all_predictions = predict_pop(ground_truth, model)\n",
    "df_pop = pd.DataFrame(list(ground_truth), columns=[\"n1\",\"n2\", \"edge\"])\n",
    "df_predict = pd.DataFrame(list(all_predictions), columns=[\"n1\",\"n2\", \"rating\"])\n",
    "# merge dataframes in order to have the same format as the other models\n",
    "df_pop = pd.merge(df_pop, df_predict, how='left', on=['n1', 'n2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    df_sorted stores the sorted top 10 (the ranking) for each node of the test set\n",
    "    and pred_friends_dict store, for each node, its sorted (by score) predicted friends. \n",
    "    \"\"\" \n",
    "    \n",
    "    lines = len(df)\n",
    "    count = 0\n",
    "    \n",
    "    # sort dataframe by n1 and ranking\n",
    "    df_sorted = df.sort_values(by=['n1','rating'], ascending=[True, False], inplace=False)\n",
    "    \n",
    "    pred_friends_dict = defaultdict(list)\n",
    "    \n",
    "    for i, row in df_sorted.iterrows():\n",
    "        n1 = row['n1']\n",
    "        n2 = row['n2']\n",
    "        edge = row['edge']\n",
    "        if len(pred_friends_dict[n1]) < 10: # get the list the friends until \n",
    "            #reaching 10 (remember that its already sorted) \n",
    "            if row['rating'] > 0: #if there is a good prediction, append\n",
    "                pred_friends_dict[n1].append(n2)\n",
    "        \n",
    "        count += 1\n",
    "        if count%100000==0:\n",
    "            print(\"{}% processed.\".format(round(count/lines,2)))\n",
    "    print(\"100% processed.\")\n",
    "    \n",
    "    return df_sorted, pred_friends_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Page-rank ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>edge</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>1</td>\n",
       "      <td>1897</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1194</td>\n",
       "      <td>1</td>\n",
       "      <td>2440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.010464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1784</td>\n",
       "      <td>1</td>\n",
       "      <td>8990</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1178</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n1    n2  edge    rating\n",
       "1565  1   1897  0     0.010766\n",
       "846   1   547   0     0.010464\n",
       "1194  1   2440  0     0.010464\n",
       "1784  1   8990  0     0.006025\n",
       "1000  1   1178  1     0.000000"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr_df_sorted, pr_pred_friends_dict = rank(df_pr)\n",
    "pr_df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adamic ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>edge</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>45.523719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1178</td>\n",
       "      <td>1</td>\n",
       "      <td>45.523719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1194</td>\n",
       "      <td>1</td>\n",
       "      <td>2440</td>\n",
       "      <td>0</td>\n",
       "      <td>45.523719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>1</td>\n",
       "      <td>1897</td>\n",
       "      <td>0</td>\n",
       "      <td>45.523719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1768</td>\n",
       "      <td>1</td>\n",
       "      <td>3152</td>\n",
       "      <td>1</td>\n",
       "      <td>45.523719</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n1    n2  edge     rating\n",
       "846   1   547   0     45.523719\n",
       "1000  1   1178  1     45.523719\n",
       "1194  1   2440  0     45.523719\n",
       "1565  1   1897  0     45.523719\n",
       "1768  1   3152  1     45.523719"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_df_sorted, ada_pred_friends_dict = rank(df_ada)\n",
    "ada_df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jaccard ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>edge</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1784</td>\n",
       "      <td>1</td>\n",
       "      <td>8990</td>\n",
       "      <td>0</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1194</td>\n",
       "      <td>1</td>\n",
       "      <td>2440</td>\n",
       "      <td>0</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>1</td>\n",
       "      <td>1897</td>\n",
       "      <td>0</td>\n",
       "      <td>0.016667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1178</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n1    n2  edge    rating\n",
       "1784  1   8990  0     0.021277\n",
       "846   1   547   0     0.020000\n",
       "1194  1   2440  0     0.020000\n",
       "1565  1   1897  0     0.016667\n",
       "1000  1   1178  1     0.000000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j_df_sorted,j_pred_friends_dict = rank(df_j)\n",
    "j_df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ALS ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>edge</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1831</td>\n",
       "      <td>1</td>\n",
       "      <td>8821</td>\n",
       "      <td>1</td>\n",
       "      <td>2.674072e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1178</td>\n",
       "      <td>1</td>\n",
       "      <td>2.779105e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1784</td>\n",
       "      <td>1</td>\n",
       "      <td>8990</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.833690e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1194</td>\n",
       "      <td>1</td>\n",
       "      <td>2440</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.996308e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>-3.033897e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n1    n2  edge        rating\n",
       "1831  1   8821  1     2.674072e-05\n",
       "1000  1   1178  1     2.779105e-08\n",
       "1784  1   8990  0    -2.833690e-05\n",
       "1194  1   2440  0    -2.996308e-05\n",
       "846   1   547   0    -3.033897e-05"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als_df_sorted,als_pred_friends_dict = rank(df_als)\n",
    "als_df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Popularity based ranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% processed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n1</th>\n",
       "      <th>n2</th>\n",
       "      <th>edge</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>547</td>\n",
       "      <td>0</td>\n",
       "      <td>4.495364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1565</td>\n",
       "      <td>1</td>\n",
       "      <td>1897</td>\n",
       "      <td>0</td>\n",
       "      <td>4.019449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1194</td>\n",
       "      <td>1</td>\n",
       "      <td>2440</td>\n",
       "      <td>0</td>\n",
       "      <td>3.662758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1178</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1768</td>\n",
       "      <td>1</td>\n",
       "      <td>3152</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      n1    n2  edge    rating\n",
       "846   1   547   0     4.495364\n",
       "1565  1   1897  0     4.019449\n",
       "1194  1   2440  0     3.662758\n",
       "1000  1   1178  1     0.000000\n",
       "1768  1   3152  1     0.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_df_sorted,pop_pred_friends_dict = rank(df_pop)\n",
    "pop_df_sorted.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "### RQ 3A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NDCG\n",
    "\n",
    "For the computation of the ndcg, the following formula has been used:\n",
    "    $$DCG = \\sum_{pos=1}^n \\frac{Rel_{pos}}{\\log_2(pos+1)}$$\n",
    "And then:\n",
    "    $$NDCG = \\frac{DCG}{iDCG}\\$$\n",
    "After that, NDCGs have been averaged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_ndcg(pred_friends_dict, ground_truth_friends_dict):\n",
    "    avg_ndcg = 0\n",
    "    count = 0\n",
    "    for node in pred_friends_dict:\n",
    "        pred_friends = pred_friends_dict[node] + [0]*10 #predicted friends and concatenation of X...\n",
    "        #... to not exceed index ranges\n",
    "        friends = ground_truth_friends_dict[node]\n",
    "        ideal_vector = ([1]*len(friends) + [0]*10)[:10] #as 1s as real friends,\n",
    "        #as 0 concatenated as positions (just in case), and the first 10 positions \n",
    "        dcg = 0\n",
    "        idcg = 0\n",
    "        for i in range(10):\n",
    "            idcg += ideal_vector[i]/np.log2(i + 1 + 1) # use index + 1 for position\n",
    "            if pred_friends[i] in friends:\n",
    "                dcg += 1/np.log2(i + 1 + 1)            \n",
    "        if idcg!=0: # if icdg = 0, pass\n",
    "            ndcg = dcg / idcg\n",
    "            avg_ndcg += ndcg\n",
    "            count += 1\n",
    "\n",
    "    return avg_ndcg/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG for Adamic: 0.6932.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average NDCG for Adamic: {}.\".format(round(compute_avg_ndcg(ada_pred_friends_dict, ground_truth_friends_dict),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG for Page-Rank: 0.1332.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average NDCG for Page-Rank: {}.\".format(round(compute_avg_ndcg(pr_pred_friends_dict, ground_truth_friends_dict),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG for Alternating Least Squares: 0.3351.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average NDCG for Alternating Least Squares: {}.\".format(round(compute_avg_ndcg(als_pred_friends_dict, ground_truth_friends_dict),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG for Jaccard similarity: 0.0532.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average NDCG for Jaccard similarity: {}.\".format(round(compute_avg_ndcg(j_pred_friends_dict, ground_truth_friends_dict),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average NDCG for Popularity-based: 0.1878.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average NDCG for Popularity-based: {}.\".format(round(compute_avg_ndcg(pop_pred_friends_dict, ground_truth_friends_dict),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision@K (P@K) \n",
    "### Personal choice\n",
    "\n",
    "Precision at k **(P@k) measures the number of relevant results among the top k documents**. We are going to average this metric for all the rankings of the same method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_avg_precision_k(pred_friends_dict, ground_truth_friends_dict, k):\n",
    "    avg_precision_k = 0\n",
    "    count = 0\n",
    "    for node in pred_friends_dict:\n",
    "        #We get a vector of 0 and 1 for each ranking \n",
    "        #(1 if there is a match between the ranking and the ground_truth_friends_dict)\n",
    "        match_vector = [int(friend in ground_truth_friends_dict[node]) for friend in list(pred_friends_dict[node])]\n",
    "        precision_k = (sum(match_vector[:k])) #get first k elements and sum them\n",
    "        avg_precision_k += precision_k\n",
    "        count += 1\n",
    "    avg_precision_k = avg_precision_k/count\n",
    "    \n",
    "    return avg_precision_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision@3 for Adamic: 0.4419.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Precision@{} for Adamic: {}.\".format(k, round(compute_avg_precision_k(ada_pred_friends_dict, ground_truth_friends_dict, k),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision@3 for Page-Rank: 0.0814.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Precision@{} for Page-Rank: {}.\".format(k, round(compute_avg_precision_k(pr_pred_friends_dict, ground_truth_friends_dict, k),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision@3 for Alternating Least Squares: 0.2267.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Precision@{} for Alternating Least Squares: {}.\".format(k, round(compute_avg_precision_k(als_pred_friends_dict, ground_truth_friends_dict, k),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision@3 for Jaccard: 0.0291.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Precision@{} for Jaccard: {}.\".format(k, round(compute_avg_precision_k(j_pred_friends_dict, ground_truth_friends_dict, k),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Precision@3 for Popularity-based: 0.1279.\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Precision@{} for Popularity-based: {}.\".format(k, round(compute_avg_precision_k(pop_pred_friends_dict, ground_truth_friends_dict, k), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
